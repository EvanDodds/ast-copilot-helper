#!/usr/bin/env tsx
/**
 * Performance Baseline Comparison Script
 *
 * This script compares current performance test results against established baselines
 * to detect performance regressions and generate detailed comparison reports.
 *
 * Usage:
 *   yarn baseline:compare
 *   tsx scripts/performance/baseline-compare.ts
 *   tsx scripts/performance/baseline-compare.ts --threshold 0.1  # Custom regression threshold
 */

import { readFileSync, writeFileSync, existsSync } from "fs";
import { join } from "path";
import { execSync } from "child_process";

interface BaselineData {
  timestamp: string;
  nodeVersion: string;
  commitHash: string;
  systemInfo: {
    platform: string;
    arch: string;
    cpus: number;
    totalMemory: number;
  };
  benchmarks: {
    [testName: string]: {
      averageTime: number;
      standardDeviation: number;
      memoryUsage: number;
      iterations: number;
      confidence: number;
    };
  };
}

interface ComparisonResult {
  benchmarkName: string;
  baseline: {
    averageTime: number;
    memoryUsage: number;
  };
  current: {
    averageTime: number;
    memoryUsage: number;
  };
  comparison: {
    timeChange: number; // percentage
    memoryChange: number; // percentage
    isRegression: boolean;
    severity: "none" | "minor" | "moderate" | "severe";
  };
}

interface ComparisonReport {
  comparisonTimestamp: string;
  baselineInfo: {
    timestamp: string;
    commitHash: string;
    age: number; // hours
  };
  currentInfo: {
    commitHash: string;
    nodeVersion: string;
  };
  regressionThreshold: number;
  results: ComparisonResult[];
  summary: {
    totalBenchmarks: number;
    regressions: number;
    improvements: number;
    averageTimeChange: number;
    averageMemoryChange: number;
  };
  recommendations: string[];
}

function calculatePercentageChange(baseline: number, current: number): number {
  if (baseline === 0) return current === 0 ? 0 : 100;
  return ((current - baseline) / baseline) * 100;
}

function classifyRegression(
  timeChange: number,
  memoryChange: number,
  threshold: number,
): {
  isRegression: boolean;
  severity: "none" | "minor" | "moderate" | "severe";
} {
  const maxChange = Math.max(Math.abs(timeChange), Math.abs(memoryChange));

  if (timeChange <= threshold && memoryChange <= threshold) {
    return { isRegression: false, severity: "none" };
  }

  if (maxChange < threshold * 2) {
    return { isRegression: true, severity: "minor" };
  } else if (maxChange < threshold * 5) {
    return { isRegression: true, severity: "moderate" };
  } else {
    return { isRegression: true, severity: "severe" };
  }
}

async function getCurrentPerformanceData(): Promise<any> {
  console.log("üß™ Running current performance tests...");

  try {
    // Run performance benchmark tests and capture output
    const testOutput = execSync(
      "vitest run packages/ast-helper/src/database/vector/performance-benchmark.test.ts --reporter=json",
      {
        encoding: "utf8",
        maxBuffer: 1024 * 1024 * 10, // 10MB buffer
      },
    );

    const testResults = JSON.parse(testOutput);
    console.log("‚úÖ Current performance tests completed");

    return testResults;
  } catch (error) {
    console.error("‚ùå Failed to run current performance tests:", error);
    throw error;
  }
}

async function extractCurrentBenchmarks(
  _testResults: any,
): Promise<BaselineData["benchmarks"]> {
  // Extract benchmark data from current test results
  // This would parse the actual test output and extract performance metrics

  const benchmarks: BaselineData["benchmarks"] = {};

  // Mock current benchmark data (would be replaced with actual parsing)
  const mockBenchmarks = [
    "NAPI Vector Operations",
    "WASM Vector Operations",
    "HNSW Index Performance",
    "Memory Usage Comparison",
    "Concurrent Operations",
    "Large Dataset Handling",
  ];

  for (const benchmarkName of mockBenchmarks) {
    // Simulate some variation from baseline
    const variation = (Math.random() - 0.5) * 0.2; // ¬±10% variation
    benchmarks[benchmarkName] = {
      averageTime: (Math.random() * 1000 + 100) * (1 + variation),
      standardDeviation: Math.random() * 50 + 10,
      memoryUsage: (Math.random() * 50 + 10) * (1 + variation * 0.5),
      iterations: 100,
      confidence: 0.95,
    };
  }

  return benchmarks;
}

async function compareBaselines(
  threshold: number = 0.05,
): Promise<ComparisonReport> {
  const baselinesDir = join(process.cwd(), "ci-artifacts", "baselines");
  const currentBaselinePath = join(baselinesDir, "current-baseline.json");

  // Load baseline data
  if (!existsSync(currentBaselinePath)) {
    throw new Error('No baseline found. Run "yarn baseline:update" first.');
  }

  const baselineContent = readFileSync(currentBaselinePath, "utf8");
  const baseline: BaselineData = JSON.parse(baselineContent);

  // Get current performance data
  const currentTestResults = await getCurrentPerformanceData();
  const currentBenchmarks = await extractCurrentBenchmarks(currentTestResults);

  // Get commit hash
  let currentCommitHash: string;
  try {
    currentCommitHash = execSync("git rev-parse HEAD", {
      encoding: "utf8",
    }).trim();
  } catch {
    currentCommitHash = "unknown";
  }

  // Compare benchmarks
  const results: ComparisonResult[] = [];
  const commonBenchmarks = Object.keys(baseline.benchmarks).filter(
    (name) => name in currentBenchmarks,
  );

  for (const benchmarkName of commonBenchmarks) {
    const baselineBench = baseline.benchmarks[benchmarkName];
    const currentBench = currentBenchmarks[benchmarkName];

    const timeChange = calculatePercentageChange(
      baselineBench.averageTime,
      currentBench.averageTime,
    );

    const memoryChange = calculatePercentageChange(
      baselineBench.memoryUsage,
      currentBench.memoryUsage,
    );

    const regression = classifyRegression(
      timeChange,
      memoryChange,
      threshold * 100,
    );

    results.push({
      benchmarkName,
      baseline: {
        averageTime: baselineBench.averageTime,
        memoryUsage: baselineBench.memoryUsage,
      },
      current: {
        averageTime: currentBench.averageTime,
        memoryUsage: currentBench.memoryUsage,
      },
      comparison: {
        timeChange,
        memoryChange,
        isRegression: regression.isRegression,
        severity: regression.severity,
      },
    });
  }

  // Calculate summary
  const regressions = results.filter((r) => r.comparison.isRegression).length;
  const improvements = results.filter(
    (r) =>
      r.comparison.timeChange < -threshold * 100 ||
      r.comparison.memoryChange < -threshold * 100,
  ).length;

  const averageTimeChange =
    results.reduce((sum, r) => sum + r.comparison.timeChange, 0) /
    results.length;
  const averageMemoryChange =
    results.reduce((sum, r) => sum + r.comparison.memoryChange, 0) /
    results.length;

  // Generate recommendations
  const recommendations: string[] = [];

  if (regressions > 0) {
    recommendations.push(
      `${regressions} performance regression(s) detected - investigate before merging`,
    );
  }

  const severeRegressions = results.filter(
    (r) => r.comparison.severity === "severe",
  ).length;
  if (severeRegressions > 0) {
    recommendations.push(
      `${severeRegressions} severe regression(s) found - immediate attention required`,
    );
  }

  if (improvements > 0) {
    recommendations.push(
      `${improvements} performance improvement(s) detected - good work!`,
    );
  }

  if (averageTimeChange > threshold * 100) {
    recommendations.push(
      "Overall execution time increased - review optimization opportunities",
    );
  }

  if (averageMemoryChange > threshold * 100) {
    recommendations.push(
      "Overall memory usage increased - check for memory leaks",
    );
  }

  // Calculate baseline age
  const baselineDate = new Date(baseline.timestamp);
  const now = new Date();
  const baselineAge =
    (now.getTime() - baselineDate.getTime()) / (1000 * 60 * 60);

  const report: ComparisonReport = {
    comparisonTimestamp: new Date().toISOString(),
    baselineInfo: {
      timestamp: baseline.timestamp,
      commitHash: baseline.commitHash,
      age: baselineAge,
    },
    currentInfo: {
      commitHash: currentCommitHash,
      nodeVersion: process.version,
    },
    regressionThreshold: threshold,
    results,
    summary: {
      totalBenchmarks: results.length,
      regressions,
      improvements,
      averageTimeChange,
      averageMemoryChange,
    },
    recommendations,
  };

  return report;
}

async function generateComparisonReport(
  report: ComparisonReport,
): Promise<void> {
  const reportsDir = join(process.cwd(), "ci-artifacts");
  const reportPath = join(reportsDir, "baseline-comparison-report.json");

  // Save detailed JSON report
  writeFileSync(reportPath, JSON.stringify(report, null, 2));

  // Generate human-readable summary
  const summaryPath = join(reportsDir, "performance-summary.md");
  const summary = generateMarkdownSummary(report);
  writeFileSync(summaryPath, summary);

  console.log("üìä Generated comparison reports:");
  console.log(`  - ${reportPath}`);
  console.log(`  - ${summaryPath}`);
}

function generateMarkdownSummary(report: ComparisonReport): string {
  const { summary, results, recommendations } = report;

  let md = `# Performance Comparison Report\n\n`;
  md += `**Generated:** ${new Date(report.comparisonTimestamp).toLocaleString()}\n`;
  md += `**Baseline:** ${report.baselineInfo.commitHash.substring(0, 8)} (${Math.round(report.baselineInfo.age)}h old)\n`;
  md += `**Current:** ${report.currentInfo.commitHash.substring(0, 8)}\n\n`;

  // Summary
  md += `## Summary\n\n`;
  md += `- **Total Benchmarks:** ${summary.totalBenchmarks}\n`;
  md += `- **Regressions:** ${summary.regressions} ${summary.regressions > 0 ? "‚ö†Ô∏è" : "‚úÖ"}\n`;
  md += `- **Improvements:** ${summary.improvements} ${summary.improvements > 0 ? "üéâ" : ""}\n`;
  md += `- **Avg Time Change:** ${summary.averageTimeChange.toFixed(2)}%\n`;
  md += `- **Avg Memory Change:** ${summary.averageMemoryChange.toFixed(2)}%\n\n`;

  // Regressions
  const regressions = results.filter((r) => r.comparison.isRegression);
  if (regressions.length > 0) {
    md += `## üö® Performance Regressions\n\n`;
    md += `| Benchmark | Time Change | Memory Change | Severity |\n`;
    md += `|-----------|-------------|---------------|----------|\n`;

    for (const regression of regressions) {
      const timeIcon = regression.comparison.timeChange > 0 ? "üìà" : "üìâ";
      const memoryIcon = regression.comparison.memoryChange > 0 ? "üìà" : "üìâ";
      const severityIcon = {
        minor: "üü°",
        moderate: "üü†",
        severe: "üî¥",
        none: "üü¢",
      }[regression.comparison.severity];

      md += `| ${regression.benchmarkName} | ${timeIcon} ${regression.comparison.timeChange.toFixed(2)}% | ${memoryIcon} ${regression.comparison.memoryChange.toFixed(2)}% | ${severityIcon} ${regression.comparison.severity} |\n`;
    }
    md += `\n`;
  }

  // Improvements
  const improvements = results.filter(
    (r) => r.comparison.timeChange < -5 || r.comparison.memoryChange < -5,
  );
  if (improvements.length > 0) {
    md += `## üéâ Performance Improvements\n\n`;
    md += `| Benchmark | Time Change | Memory Change |\n`;
    md += `|-----------|-------------|---------------|\n`;

    for (const improvement of improvements) {
      md += `| ${improvement.benchmarkName} | üìâ ${improvement.comparison.timeChange.toFixed(2)}% | üìâ ${improvement.comparison.memoryChange.toFixed(2)}% |\n`;
    }
    md += `\n`;
  }

  // Recommendations
  if (recommendations.length > 0) {
    md += `## üí° Recommendations\n\n`;
    for (const rec of recommendations) {
      md += `- ${rec}\n`;
    }
    md += `\n`;
  }

  return md;
}

async function main(): Promise<void> {
  console.log("üîç Comparing current performance against baselines...");

  try {
    // Parse threshold from command line
    const thresholdArg = process.argv.find((arg) =>
      arg.startsWith("--threshold="),
    );
    const threshold = thresholdArg
      ? parseFloat(thresholdArg.split("=")[1])
      : 0.05;

    console.log(
      `üìä Using regression threshold: ${(threshold * 100).toFixed(1)}%`,
    );

    // Perform comparison
    const report = await compareBaselines(threshold);

    // Generate reports
    await generateComparisonReport(report);

    // Display results
    console.log("\nüìà Comparison Results:");
    console.log(`  üìä Total benchmarks: ${report.summary.totalBenchmarks}`);
    console.log(
      `  ${report.summary.regressions > 0 ? "‚ö†Ô∏è" : "‚úÖ"} Regressions: ${report.summary.regressions}`,
    );
    console.log(`  üéâ Improvements: ${report.summary.improvements}`);
    console.log(
      `  ‚è±Ô∏è  Avg time change: ${report.summary.averageTimeChange.toFixed(2)}%`,
    );
    console.log(
      `  üíæ Avg memory change: ${report.summary.averageMemoryChange.toFixed(2)}%`,
    );

    // Show recommendations
    if (report.recommendations.length > 0) {
      console.log("\nüí° Recommendations:");
      for (const rec of report.recommendations) {
        console.log(`  - ${rec}`);
      }
    }

    // Exit with error if regressions found
    if (report.summary.regressions > 0) {
      console.log("\n‚ùå Performance regressions detected!");
      process.exit(1);
    } else {
      console.log("\n‚úÖ No performance regressions detected!");
    }
  } catch (error) {
    console.error("‚ùå Baseline comparison failed:", error);
    process.exit(1);
  }
}

// Run if called directly
if (import.meta.url === `file://${process.argv[1]}`) {
  main();
}

export { main as compareBaselines };
