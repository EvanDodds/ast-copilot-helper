import { describe, it, expect, beforeEach, afterEach } from 'vitest';
import { ParsingBenchmarkRunner } from '../../../packages/ast-helper/src/performance/parsing-benchmarks';
import type { ParsingBenchmarkConfig, NodeCount } from '../../../packages/ast-helper/src/performance/types';

describe('Parsing Performance Benchmarks', () => {
  let runner: ParsingBenchmarkRunner;

  beforeEach(() => {
    runner = new ParsingBenchmarkRunner();
  });

  afterEach(() => {
    // Clean up any resources
  });

  describe('ParsingBenchmarkRunner', () => {
    describe('initialization', () => {
      it('should create runner instance successfully', () => {
        expect(runner).toBeInstanceOf(ParsingBenchmarkRunner);
      });
    });

    describe('TypeScript parsing benchmarks', () => {
      it('should parse small TypeScript codebases within performance targets', async () => {
        const config: ParsingBenchmarkConfig = {
          nodeCount: 'small',
          language: 'typescript',
          iterations: 3,
          timeout: 30000
        };

        const result = await runner.runParsingBenchmarks(config);

        expect(result.benchmarkType).toBe('parsing_benchmark');
        expect(result.successfulRuns).toBe(3);
        expect(result.failedRuns).toBe(0);
        expect(result.totalRuns).toBe(3);
        expect(result.averageThroughput).toBeGreaterThan(0);
        expect(result.errors).toHaveLength(0);
      });

      it('should parse medium TypeScript codebases efficiently', async () => {
        const config: ParsingBenchmarkConfig = {
          nodeCount: 'medium',
          language: 'typescript',
          iterations: 2,
          timeout: 60000
        };

        const result = await runner.runParsingBenchmarks(config);

        expect(result.successfulRuns).toBe(2);
        expect(result.failedRuns).toBe(0);
        expect(result.averageDuration).toBeGreaterThan(0);
        expect(result.averageThroughput).toBeGreaterThan(0);
      });

      it('should handle large TypeScript codebases with acceptable performance', async () => {
        const config: ParsingBenchmarkConfig = {
          nodeCount: 'large',
          language: 'typescript',
          iterations: 1,
          timeout: 120000
        };

        const result = await runner.runParsingBenchmarks(config);

        expect(result.successfulRuns).toBeGreaterThan(0);
        expect(result.averageThroughput).toBeGreaterThan(0);
        
        // Large codebases might generate warnings, but should not fail
        if (result.status === 'warning') {
          expect(result.warnings.length).toBeGreaterThan(0);
        }
      });
    });

    describe('Python parsing benchmarks', () => {
      it('should parse Python codebases efficiently', async () => {
        const config: ParsingBenchmarkConfig = {
          nodeCount: 'medium',
          language: 'python',
          iterations: 2,
          timeout: 60000
        };

        const result = await runner.runParsingBenchmarks(config);

        expect(result.successfulRuns).toBe(2);
        expect(result.failedRuns).toBe(0);
        expect(result.averageThroughput).toBeGreaterThan(0);
      });

      it('should generate appropriate Python test data', async () => {
        const config: ParsingBenchmarkConfig = {
          nodeCount: 1000,
          language: 'python',
          iterations: 1
        };

        const result = await runner.runParsingBenchmarks(config);

        expect(result.successfulRuns).toBe(1);
        expect(result.failedRuns).toBe(0);
      });
    });

    describe('JavaScript parsing benchmarks', () => {
      it('should parse JavaScript codebases within targets', async () => {
        const config: ParsingBenchmarkConfig = {
          nodeCount: 'small',
          language: 'javascript',
          iterations: 3
        };

        const result = await runner.runParsingBenchmarks(config);

        expect(result.status).toMatch(/^(passed|warning)$/);
        expect(result.successRate).toBe(1.0);
        expect(result.metrics.memoryUsed).toBeDefined();
        expect(result.metrics.cpuUsage).toBeGreaterThanOrEqual(0);
      });
    });

    describe('Java parsing benchmarks', () => {
      it('should parse Java codebases efficiently', async () => {
        const config: ParsingBenchmarkConfig = {
          nodeCount: 'medium',
          language: 'java',
          iterations: 2
        };

        const result = await runner.runParsingBenchmarks(config);

        expect(result.status).toMatch(/^(passed|warning)$/);
        expect(result.successRate).toBe(1.0);
        expect(result.details.language).toBe('java');
      });
    });

    describe('performance validation', () => {
      it('should meet 100k node parsing target within 5 minutes', async () => {
        const config: ParsingBenchmarkConfig = {
          nodeCount: 100000,
          language: 'typescript',
          iterations: 1,
          timeout: 300000 // 5 minutes
        };

        const result = await runner.runParsingBenchmarks(config);

        expect(result.successRate).toBeGreaterThan(0);
        
        // Should either pass or warn, but not fail completely
        expect(result.status).not.toBe('failed');
        
        if (result.metrics.parseTime) {
          // If it exceeds 5 minutes, should be in warnings
          if (result.metrics.parseTime > 300000) {
            expect(result.warnings.length).toBeGreaterThan(0);
            expect(result.warnings.some((w: string) => w.includes('5 minute'))).toBe(true);
          }
        }
      });

      it('should achieve minimum throughput target of 300 nodes/second', async () => {
        const config: ParsingBenchmarkConfig = {
          nodeCount: 'medium',
          language: 'typescript',
          iterations: 3
        };

        const result = await runner.runParsingBenchmarks(config);

        expect(result.successRate).toBe(1.0);
        
        // If throughput is below 300 nodes/sec, should be in warnings
        if (result.metrics.throughput < 300) {
          expect(result.warnings.some((w: string) => w.includes('300 nodes/sec'))).toBe(true);
        } else {
          expect(result.metrics.throughput).toBeGreaterThanOrEqual(300);
        }
      });

      it('should maintain reasonable memory usage', async () => {
        const config: ParsingBenchmarkConfig = {
          nodeCount: 'large',
          language: 'typescript',
          iterations: 1
        };

        const result = await runner.runParsingBenchmarks(config);

        expect(result.successRate).toBeGreaterThan(0);
        
        // Check memory usage is tracked
        expect(result.metrics.memoryUsed).toBeDefined();
        expect(result.details.peakMemoryMB).toBeDefined();
        
        // If memory usage is high, should be in warnings
        const memoryMB = result.details.peakMemoryMB as number;
        if (memoryMB > 1024) {
          expect(result.warnings.some((w: string) => w.includes('memory usage'))).toBe(true);
        }
      });
    });

    describe('node count handling', () => {
      it('should handle different NodeCount types', async () => {
        const nodeCountTypes: NodeCount[] = ['small', 'medium', 'large', 1500];

        for (const nodeCount of nodeCountTypes) {
          const config: ParsingBenchmarkConfig = {
            nodeCount,
            language: 'typescript',
            iterations: 1
          };

          const result = await runner.runParsingBenchmarks(config);

          expect(result.successRate).toBeGreaterThan(0);
          expect(result.details.targetNodeCount).toBe(nodeCount);
        }
      });
    });

    describe('error handling', () => {
      it('should handle parsing failures gracefully', async () => {
        // Create a config that might cause issues
        const config: ParsingBenchmarkConfig = {
          nodeCount: 'xlarge',
          language: 'unknown-language',
          iterations: 1,
          timeout: 1000 // Very short timeout
        };

        const result = await runner.runParsingBenchmarks(config);

        // Should not throw, but may fail or warn
        expect(result).toBeDefined();
        expect(result.name).toBe('parsing_benchmark');
        expect(['passed', 'warning', 'failed']).toContain(result.status);
        
        if (result.status === 'failed') {
          expect(result.successRate).toBeLessThan(1.0);
          expect(result.errors.length).toBeGreaterThan(0);
        }
      });
    });

    describe('multi-language support', () => {
      const languages = ['typescript', 'javascript', 'python', 'java'];

      languages.forEach(language => {
        it(`should support ${language} parsing benchmarks`, async () => {
          const config: ParsingBenchmarkConfig = {
            nodeCount: 'small',
            language,
            iterations: 2
          };

          const result = await runner.runParsingBenchmarks(config);

          expect(result.details.language).toBe(language);
          expect(result.successRate).toBeGreaterThan(0);
        });
      });
    });

    describe('benchmark metrics validation', () => {
      it('should provide comprehensive performance metrics', async () => {
        const config: ParsingBenchmarkConfig = {
          nodeCount: 'medium',
          language: 'typescript',
          iterations: 3
        };

        const result = await runner.runParsingBenchmarks(config);

        // Validate all required metrics are present
        expect(result.metrics).toBeDefined();
        expect(result.metrics.averageDuration).toBeGreaterThan(0);
        expect(result.metrics.minDuration).toBeGreaterThanOrEqual(0);
        expect(result.metrics.maxDuration).toBeGreaterThanOrEqual(result.metrics.minDuration);
        expect(result.metrics.throughput).toBeGreaterThan(0);
        expect(result.metrics.memoryUsed).toBeDefined();
        expect(result.metrics.cpuUsage).toBeGreaterThanOrEqual(0);
        
        if (result.metrics.parseTime) {
          expect(result.metrics.parseTime).toBeGreaterThan(0);
        }
      });

      it('should track performance across multiple iterations', async () => {
        const config: ParsingBenchmarkConfig = {
          nodeCount: 'small',
          language: 'typescript',
          iterations: 5
        };

        const result = await runner.runParsingBenchmarks(config);

        expect(result.iterations).toBe(5);
        expect(result.successRate).toBe(1.0);
        
        // With multiple iterations, we should see variance
        expect(result.metrics.maxDuration).toBeGreaterThanOrEqual(result.metrics.minDuration);
      });
    });
  });
});